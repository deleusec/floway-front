import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import { useAuth } from '@/stores/auth';
import { NODE_URL } from '@/constants/env';

type AudioMessage = {
  type: 'text' | 'audio' | 'internal';
  content: string; // text pour Speech ou nom du fichier pour audio
  priority: 'high' | 'normal' | 'low'; // high = internal, normal = √©v√©nements utilisateur, low = autres
};

class AudioManager {
  private queue: AudioMessage[] = [];
  private isPlaying = false;
  private currentSound: Audio.Sound | null = null;

  // Ajoute un message √† la queue
  addToQueue(message: AudioMessage) {
    console.log('üéµ Audio manager - Ajout √† la queue:', message);
    
    // Si c'est priorit√© haute (internal), on l'ins√®re au d√©but
    if (message.priority === 'high') {
      this.queue.unshift(message);
    } else {
      this.queue.push(message);
    }
    
    this.processQueue();
  }

  // M√©thodes publiques simplifi√©es
  speakText(text: string, priority: 'high' | 'normal' | 'low' = 'normal') {
    this.addToQueue({
      type: 'text',
      content: text,
      priority
    });
  }

  playAudio(audioName: string, priority: 'high' | 'normal' | 'low' = 'normal') {
    this.addToQueue({
      type: 'audio',
      content: audioName,
      priority
    });
  }

  speakInternal(text: string) {
    this.addToQueue({
      type: 'internal',
      content: text,
      priority: 'high'
    });
  }

  // Traite la file d'attente
  private async processQueue() {
    if (this.isPlaying || this.queue.length === 0) return;
    
    const next = this.queue.shift();
    if (!next) return;

    console.log('üéµ Audio manager - Traitement:', next);
    this.isPlaying = true;

    try {
      if (next.type === 'text' || next.type === 'internal') {
        // Lecture texte avec Speech
        await this.speakTextMessage(next.content);
      } else if (next.type === 'audio') {
        // Lecture fichier audio
        await this.playAudioFile(next.content);
      }
    } catch (error) {
      console.error('‚ùå Erreur lors de la lecture audio:', error);
    } finally {
      this.isPlaying = false;
      // Continuer avec le prochain √©l√©ment
      this.processQueue();
    }
  }

  // Lecture texte avec Speech
  private async speakTextMessage(text: string): Promise<void> {
    return new Promise<void>((resolve, reject) => {
      Speech.speak(text, {
        language: 'fr-FR',
        onDone: () => {
          console.log('‚úÖ Speech termin√©');
          resolve();
        },
        onStopped: () => {
          console.log('‚èπÔ∏è Speech arr√™t√©');
          resolve();
        },
        onError: (error) => {
          console.error('‚ùå Erreur Speech:', error);
          reject(error);
        }
      });
    });
  }

  // Lecture d'un fichier audio
  private async playAudioFile(audioName: string): Promise<void> {
    try {
      console.log('üéµ T√©l√©chargement audio:', audioName);
      
      const { token } = useAuth.getState();
      if (!token) {
        console.error('‚ùå Token manquant pour l\'audio');
        return;
      }

      const response = await fetch(`${NODE_URL}/auth/audio/${audioName}?authorization=${token}`, {
        method: 'GET',
      });

      if (!response.ok) {
        console.error('‚ùå Erreur t√©l√©chargement audio:', response.status);
        return;
      }

      const audioArrayBuffer = await response.arrayBuffer();
      const fileExtension = audioName.split('.').pop() || 'm4a';
      const tempFileName = `temp_audio_${Date.now()}.${fileExtension}`;
      const tempUri = `${FileSystem.documentDirectory}${tempFileName}`;
      
      // Convertir en base64 et sauvegarder
      const binary = new Uint8Array(audioArrayBuffer);
      let base64String = '';
      for (let i = 0; i < binary.length; i++) {
        base64String += String.fromCharCode(binary[i]);
      }
      const base64Data = btoa(base64String);
      
      await FileSystem.writeAsStringAsync(tempUri, base64Data, {
        encoding: FileSystem.EncodingType.Base64,
      });
      
      console.log('üéµ Fichier temporaire cr√©√©:', tempUri);
      
      // Jouer l'audio
      const { sound } = await Audio.Sound.createAsync(
        { uri: tempUri },
        { shouldPlay: true }
      );

      this.currentSound = sound;
      console.log('üéµ Lecture audio en cours');

      // Attendre la fin de la lecture
      await new Promise<void>((resolve) => {
        sound.setOnPlaybackStatusUpdate((status) => {
          if (status.isLoaded && status.didJustFinish) {
            console.log('‚úÖ Lecture audio termin√©e');
            sound.unloadAsync();
            this.currentSound = null;
            // Supprimer le fichier temporaire
            FileSystem.deleteAsync(tempUri).catch(console.error);
            resolve();
          }
        });
      });
      
    } catch (error) {
      console.error('‚ùå Erreur lecture fichier audio:', error);
      throw error;
    }
  }

  // Stoppe tout et vide la queue
  async stop() {
    console.log('üõë Arr√™t audio manager');
    
    // Arr√™ter Speech
    Speech.stop();
    
    // Arr√™ter l'audio en cours
    if (this.currentSound) {
      try {
        await this.currentSound.unloadAsync();
        this.currentSound = null;
      } catch (error) {
        console.error('Erreur lors de l\'arr√™t de l\'audio:', error);
      }
    }
    
    // Vider la queue et r√©initialiser l'√©tat
    this.queue = [];
    this.isPlaying = false;
  }

  // Vide la queue sans arr√™ter la lecture en cours
  clearQueue() {
    console.log('üóëÔ∏è Vidage de la queue audio');
    this.queue = [];
  }

  // Getters pour l'√©tat
  get playing() {
    return this.isPlaying;
  }

  get queueLength() {
    return this.queue.length;
  }
}

// Instance globale
export const audioManager = new AudioManager();

// Export de type pour TypeScript
export type { AudioMessage };